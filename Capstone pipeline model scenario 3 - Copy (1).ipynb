{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595747415676",
   "display_name": "Python 3.7.6 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "time: 2.9 s\n"
    }
   ],
   "source": [
    "df = pd.read_csv('Capstone_model_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       index      race  gender       age  admission_type_id  \\\n0          1  0.240931       0  0.151549           0.243674   \n1          5  0.240931       1  0.219908           0.242545   \n2          7  0.240931       1  0.244659           0.243674   \n3         10  0.245193       0  0.238560           0.243674   \n4         11  0.245193       1  0.240600           0.242545   \n...      ...       ...     ...       ...                ...   \n71085  12469  0.240931       1  0.241170           0.249835   \n71086  72575  0.240931       0  0.241405           0.252307   \n71087   6517  0.243329       1  0.238560           0.249523   \n71088  92986  0.240931       0  0.242545           0.249283   \n71089   9199  0.243994       0  0.241742           0.243674   \n\n       discharge_disposition_id  admission_source_id    diag_1    diag_2  \\\n0                      0.206571             0.236728  0.263696  0.289953   \n1                      0.206571             0.263651  0.231501  0.206477   \n2                      0.206571             0.236728  0.234254  0.212776   \n3                      0.206571             0.236728  0.250146  0.231240   \n4                      0.206571             0.314975  0.285527  0.214526   \n...                         ...                  ...       ...       ...   \n71085                  0.308873             0.241521  0.350876  0.237429   \n71086                  0.206571             0.243443  0.224244  0.218394   \n71087                  0.319038             0.241278  0.269767  0.234706   \n71088                  0.219715             0.241091  0.262024  0.229568   \n71089                  0.280087             0.236728  0.234254  0.271454   \n\n         diag_3  ...  rosiglitazone   insulin  change  diabetesMed  \\\n0      0.345712  ...       0.243954  0.252058       1            0   \n1      0.234852  ...       0.243954  0.246712       0            0   \n2      0.234852  ...       0.243954  0.229703       0            0   \n3      0.290121  ...       0.243954  0.246712       0            0   \n4      0.398817  ...       0.243954  0.246712       1            0   \n...         ...  ...            ...       ...     ...          ...   \n71085  0.247951  ...       0.243954  0.239434       0            0   \n71086  0.259376  ...       0.243954  0.233078       0            0   \n71087  0.217541  ...       0.243954  0.237475       0            0   \n71088  0.351165  ...       0.243954  0.237853       0            0   \n71089  0.275740  ...       0.243954  0.235993       1            0   \n\n       time_in_hospital  num_medications  number_diagnoses  num_ovrll_prcdrs  \\\n0             -0.353541         0.352067          0.788793          0.699943   \n1             -0.353541         0.095211          0.788793         -0.429853   \n2              0.414600        -0.489932          0.022613          1.430210   \n3              1.364225         0.226131          0.788793          0.183321   \n4              0.951862        -0.655536         -0.603491          0.855788   \n...                 ...              ...               ...               ...   \n71085          0.721962         1.130808          0.788793          0.613429   \n71086         -0.906393        -0.746248          0.022613         -1.482995   \n71087         -0.353541        -0.407819         -0.776990         -0.729237   \n71088         -0.135076         0.314446         -0.396589         -0.260814   \n71089         -0.534686        -0.071351         -0.570228         -0.065269   \n\n       num_prvs_vists  readmitted  \n0           -1.052481           0  \n1           -1.052481           0  \n2           -1.052481           0  \n3           -1.052481           0  \n4           -1.052481           1  \n...               ...         ...  \n71085        0.222471           1  \n71086       -0.030516           1  \n71087       -0.226008           1  \n71088        1.158414           1  \n71089        0.247292           1  \n\n[71090 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>race</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>admission_type_id</th>\n      <th>discharge_disposition_id</th>\n      <th>admission_source_id</th>\n      <th>diag_1</th>\n      <th>diag_2</th>\n      <th>diag_3</th>\n      <th>...</th>\n      <th>rosiglitazone</th>\n      <th>insulin</th>\n      <th>change</th>\n      <th>diabetesMed</th>\n      <th>time_in_hospital</th>\n      <th>num_medications</th>\n      <th>number_diagnoses</th>\n      <th>num_ovrll_prcdrs</th>\n      <th>num_prvs_vists</th>\n      <th>readmitted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.240931</td>\n      <td>0</td>\n      <td>0.151549</td>\n      <td>0.243674</td>\n      <td>0.206571</td>\n      <td>0.236728</td>\n      <td>0.263696</td>\n      <td>0.289953</td>\n      <td>0.345712</td>\n      <td>...</td>\n      <td>0.243954</td>\n      <td>0.252058</td>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.353541</td>\n      <td>0.352067</td>\n      <td>0.788793</td>\n      <td>0.699943</td>\n      <td>-1.052481</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>0.240931</td>\n      <td>1</td>\n      <td>0.219908</td>\n      <td>0.242545</td>\n      <td>0.206571</td>\n      <td>0.263651</td>\n      <td>0.231501</td>\n      <td>0.206477</td>\n      <td>0.234852</td>\n      <td>...</td>\n      <td>0.243954</td>\n      <td>0.246712</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.353541</td>\n      <td>0.095211</td>\n      <td>0.788793</td>\n      <td>-0.429853</td>\n      <td>-1.052481</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>0.240931</td>\n      <td>1</td>\n      <td>0.244659</td>\n      <td>0.243674</td>\n      <td>0.206571</td>\n      <td>0.236728</td>\n      <td>0.234254</td>\n      <td>0.212776</td>\n      <td>0.234852</td>\n      <td>...</td>\n      <td>0.243954</td>\n      <td>0.229703</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.414600</td>\n      <td>-0.489932</td>\n      <td>0.022613</td>\n      <td>1.430210</td>\n      <td>-1.052481</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10</td>\n      <td>0.245193</td>\n      <td>0</td>\n      <td>0.238560</td>\n      <td>0.243674</td>\n      <td>0.206571</td>\n      <td>0.236728</td>\n      <td>0.250146</td>\n      <td>0.231240</td>\n      <td>0.290121</td>\n      <td>...</td>\n      <td>0.243954</td>\n      <td>0.246712</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.364225</td>\n      <td>0.226131</td>\n      <td>0.788793</td>\n      <td>0.183321</td>\n      <td>-1.052481</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>0.245193</td>\n      <td>1</td>\n      <td>0.240600</td>\n      <td>0.242545</td>\n      <td>0.206571</td>\n      <td>0.314975</td>\n      <td>0.285527</td>\n      <td>0.214526</td>\n      <td>0.398817</td>\n      <td>...</td>\n      <td>0.243954</td>\n      <td>0.246712</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.951862</td>\n      <td>-0.655536</td>\n      <td>-0.603491</td>\n      <td>0.855788</td>\n      <td>-1.052481</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>71085</th>\n      <td>12469</td>\n      <td>0.240931</td>\n      <td>1</td>\n      <td>0.241170</td>\n      <td>0.249835</td>\n      <td>0.308873</td>\n      <td>0.241521</td>\n      <td>0.350876</td>\n      <td>0.237429</td>\n      <td>0.247951</td>\n      <td>...</td>\n      <td>0.243954</td>\n      <td>0.239434</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.721962</td>\n      <td>1.130808</td>\n      <td>0.788793</td>\n      <td>0.613429</td>\n      <td>0.222471</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>71086</th>\n      <td>72575</td>\n      <td>0.240931</td>\n      <td>0</td>\n      <td>0.241405</td>\n      <td>0.252307</td>\n      <td>0.206571</td>\n      <td>0.243443</td>\n      <td>0.224244</td>\n      <td>0.218394</td>\n      <td>0.259376</td>\n      <td>...</td>\n      <td>0.243954</td>\n      <td>0.233078</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.906393</td>\n      <td>-0.746248</td>\n      <td>0.022613</td>\n      <td>-1.482995</td>\n      <td>-0.030516</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>71087</th>\n      <td>6517</td>\n      <td>0.243329</td>\n      <td>1</td>\n      <td>0.238560</td>\n      <td>0.249523</td>\n      <td>0.319038</td>\n      <td>0.241278</td>\n      <td>0.269767</td>\n      <td>0.234706</td>\n      <td>0.217541</td>\n      <td>...</td>\n      <td>0.243954</td>\n      <td>0.237475</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.353541</td>\n      <td>-0.407819</td>\n      <td>-0.776990</td>\n      <td>-0.729237</td>\n      <td>-0.226008</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>71088</th>\n      <td>92986</td>\n      <td>0.240931</td>\n      <td>0</td>\n      <td>0.242545</td>\n      <td>0.249283</td>\n      <td>0.219715</td>\n      <td>0.241091</td>\n      <td>0.262024</td>\n      <td>0.229568</td>\n      <td>0.351165</td>\n      <td>...</td>\n      <td>0.243954</td>\n      <td>0.237853</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.135076</td>\n      <td>0.314446</td>\n      <td>-0.396589</td>\n      <td>-0.260814</td>\n      <td>1.158414</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>71089</th>\n      <td>9199</td>\n      <td>0.243994</td>\n      <td>0</td>\n      <td>0.241742</td>\n      <td>0.243674</td>\n      <td>0.280087</td>\n      <td>0.236728</td>\n      <td>0.234254</td>\n      <td>0.271454</td>\n      <td>0.275740</td>\n      <td>...</td>\n      <td>0.243954</td>\n      <td>0.235993</td>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.534686</td>\n      <td>-0.071351</td>\n      <td>-0.570228</td>\n      <td>-0.065269</td>\n      <td>0.247292</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>71090 rows Ã— 27 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "time: 419 ms\n"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "time: 50 ms\n"
    }
   ],
   "source": [
    "X = df.drop('readmitted',axis=1)\n",
    "y = df['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "time: 2.05 ms\n"
    }
   ],
   "source": [
    "from pyforest import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport numpy as np'); }\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "time: 150 ms\n"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "time: 25.5 ms\n"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "time: 10 ms\n"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from sklearn.svm import SVC\n",
    "import hyperopt as hp\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport numpy as np'); }\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport numpy as np'); }\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport numpy as np'); }\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport numpy as np'); }\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport numpy as np'); }\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport numpy as np'); }\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport numpy as np'); }\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport numpy as np'); }\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport numpy as np'); }\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport numpy as np'); }\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport numpy as np'); }\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport numpy as np'); }\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "time: 158 ms\n"
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "pipe = Pipeline([(\"classifier\", XGBClassifier())])\n",
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "r_param = [{\"classifier\": [LogisticRegression()],\n",
    "                 \"classifier__penalty\": ['l2','l1'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10)},\n",
    "               {\"classifier\": [LogisticRegression()],\n",
    "                 \"classifier__penalty\": ['l2'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10),\n",
    "                 \"classifier__solver\":['newton-cg','saga','sag','liblinear'] ##This solvers don't allow L1 penalty\n",
    "                 },\n",
    "            {\"classifier\": [DecisionTreeClassifier()],\n",
    "             \"classifier__criterion\":['gini','entropy'],\n",
    "                 \"classifier__max_depth\":[5,8,15,25,30,None],\n",
    "                 \"classifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
    "                 \"classifier__max_leaf_nodes\": [2, 5,10]},\n",
    "               {\"classifier\": [RandomForestClassifier()],\n",
    "                 \"classifier__n_estimators\": [10, 100, 1000],\n",
    "                 \"classifier__max_depth\":[5,8,15,25,30,None],\n",
    "                 \"classifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
    "                 \"classifier__max_leaf_nodes\": [2, 5,10]},\n",
    "           {'classifier':[LGBMClassifier()],\n",
    "            'classifier__n_estimators':np.arange(50,250,5),\n",
    "            'classifier__max_depth':np.arange(2,15,5),\n",
    "            'classifier__num_leaves':np.arange(2,60,5)},\n",
    "           {'classifier':[XGBClassifier()],\n",
    "              \"classifier__learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "            \"classifier__min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "            \"classifier__gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "            \"classifier__colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]},\n",
    "           #{'classifier':[SGDClassifier()],                                     ##Stocasticated Gradient decent\n",
    "            #\"classifier__C\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0],\n",
    "            #\"classifier__penalty\": ['l2']},\n",
    "           {'classifier':[AdaBoostClassifier()],        ## Adaboost Classifier\n",
    "           \"classifier__n_estimators\": sp_randint(50,250), \n",
    "            'classifier__learning_rate': [(0.97 + x / 100) for x in range(0, 8)],\n",
    "            'classifier__algorithm': ['SAMME', 'SAMME.R']},\n",
    "           {'classifier':[KNN()],\n",
    "            \"classifier__weights\":['uniform','distance'],\n",
    "            'classifier__n_neighbors':np.arange(1,40),\n",
    "            'classifier__leaf_size':np.arange(2,40)},\n",
    "           {'classifier':[SVC()],                        ## SVM Algorithm\n",
    "           'classifier__gamma':np.logspace(-4,2,10000),\n",
    "       'classifier__C':np.logspace(-2,2,10000)},\n",
    "           {\"classifier\":[GradientBoostingClassifier()],\n",
    "            \"classifier__learning_rate\":np.arange(0,0.5,15),\n",
    "            \"classifier__n_estimators\":np.arange(50,250,5),\n",
    "            'classifier__max_depth':np.arange(2,15,5),\n",
    "            \"classifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
    "            \"classifier__max_leaf_nodes\": [2, 5,10]}\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "time: 2 ms\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "time: 5 ms\n"
    }
   ],
   "source": [
    "rsearch = RandomizedSearchCV(pipe, r_param, cv=5, verbose=0,n_jobs=-1,random_state=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_r = rsearch.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Pipeline(steps=[('classifier',\n                 LGBMClassifier(max_depth=12, n_estimators=240,\n                                num_leaves=22))])\nThe mean accuracy of the model is through randomized search is : 0.8425001172223003\ntime: 614 ms\n"
    }
   ],
   "source": [
    "print(best_model_r.best_estimator_)\n",
    "print(\"The mean accuracy of the model is through randomized search is :\",best_model_r.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "time: 2 ms\n"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,roc_curve,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'classifier': LGBMClassifier(max_depth=12, n_estimators=240, num_leaves=22),\n 'classifier__max_depth': 12,\n 'classifier__n_estimators': 240,\n 'classifier__num_leaves': 22}"
     },
     "metadata": {},
     "execution_count": 15
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "time: 6 ms\n"
    }
   ],
   "source": [
    "best_model_r.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Confusion Matrix-Train\n [[24626   233]\n [ 6686 18218]]\nAccuracy Score-Train\n 0.8609609549263509\nClassification Report-Train\n               precision    recall  f1-score   support\n\n           0       0.79      0.99      0.88     24859\n           1       0.99      0.73      0.84     24904\n\n    accuracy                           0.86     49763\n   macro avg       0.89      0.86      0.86     49763\nweighted avg       0.89      0.86      0.86     49763\n\n\n\n\nConfusion Matrix-Test\n [[10411   275]\n [ 3084  7557]]\nAccuracy Score-Test\n 0.8425001172223003\nClassification Report-Test\n               precision    recall  f1-score   support\n\n           0       0.77      0.97      0.86     10686\n           1       0.96      0.71      0.82     10641\n\n    accuracy                           0.84     21327\n   macro avg       0.87      0.84      0.84     21327\nweighted avg       0.87      0.84      0.84     21327\n\ntime: 53.9 s\n"
    }
   ],
   "source": [
    "rfc=LGBMClassifier(max_depth=12, n_estimators=240,\n",
    "                                num_leaves=22,random_state=96)\n",
    "rfc.fit(X_train,y_train)\n",
    "y_train_pred=rfc.predict(X_train)\n",
    "y_train_prob=rfc.predict_proba(X_train)[:,1]\n",
    "\n",
    "y_test_pred=rfc.predict(X_test)\n",
    "y_test_prob=rfc.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Confusion Matrix-Train\\n',confusion_matrix(y_train,y_train_pred))\n",
    "print('Accuracy Score-Train\\n',accuracy_score(y_train,y_train_pred))\n",
    "print('Classification Report-Train\\n',classification_report(y_train,y_train_pred))\n",
    "\n",
    "print('\\n'*2)\n",
    "print('Confusion Matrix-Test\\n',confusion_matrix(y_test,y_test_pred))\n",
    "print('Accuracy Score-Test\\n',accuracy_score(y_test,y_test_pred))\n",
    "print('Classification Report-Test\\n',classification_report(y_test,y_test_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "time: 5 ms\n"
    }
   ],
   "source": [
    "lgbm=LGBMClassifier(max_depth=12, n_estimators=240,\n",
    "                                num_leaves=22,random_state=96)\n",
    "models=[]\n",
    "models.append(('lgbm',lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotliib'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyforest\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotliib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotliib'"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "time: 3 ms\n"
    }
   ],
   "source": [
    "def algorithim_boxplot_comparison(X,\n",
    "                                  y,\n",
    "                                  algo_list=[],\n",
    "                                  random_state=3,\n",
    "                                  scoring='accuracy',\n",
    "                                  n_splits=10):\n",
    "    \"\"\"To compare metric of different algorithims\n",
    "       Paramters-\n",
    "       algo_list : a list conataining algorithim models like random forest,\n",
    "                     decision trees etc.\n",
    "       X : dataframe without Target variable\n",
    "       y : dataframe with only Target variable\n",
    "       random_state : The seed of randomness. Default is 3\n",
    "       n_splits : Number of splits used. Default is 3\n",
    "       ( Default changes from organization to organization)\n",
    "       Returns-\n",
    "       mean accuracy and the standard deviation accuracy.\n",
    "       Box Plot of Acuuracy\"\"\"\n",
    "\n",
    "    results = []\n",
    "    names = []\n",
    "    for algo_name, algo_model in algo_list:\n",
    "        kfold = model_selection.KFold(shuffle=True,\n",
    "                                      n_splits=n_splits,\n",
    "                                      random_state=random_state)\n",
    "        cv_results = model_selection.cross_val_score(algo_model,\n",
    "                                                     X,\n",
    "                                                     y,\n",
    "                                                     cv=kfold,\n",
    "                                                     scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(algo_name)\n",
    "        msg = \"%s: %s : (%f) %s : (%f) %s : (%f)\" % (\n",
    "            algo_name, 'median', np.median(cv_results), 'bias',\n",
    "            1-np.mean(cv_results), 'variance', cv_results.var(ddof=1))\n",
    "        print(msg)\n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Algorithm Comparison')\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot(results)\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algorithim_boxplot_comparison(X,y,algo_list=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}